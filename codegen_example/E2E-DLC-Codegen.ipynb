{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4724019",
   "metadata": {},
   "source": [
    "# < CANNOT BE USED FOR PRODUCTION >\n",
    "# Codegen Sagemaker inference with Intel optimizations\n",
    "\n",
    "## Agenda\n",
    "0. Prerequisites\n",
    "1. Build Deep Learning Container and push it to AWS ECR\n",
    "2. Create a Torchserve file and put it on S3 bucket\n",
    "3. Create AWS Sagemaker endpoint\n",
    "4. Invoke the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a82916",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "Install all libraries required to run the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e41ae516",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"sagemaker>=2.175.0\" --upgrade --quiet\n",
    "! pip install awscli boto3 botocore numpy s3transfer torch-model-archiver==0.8.1 torchserve==0.8.2 --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a1ae90",
   "metadata": {},
   "source": [
    "Remember also that you have all required accesses on you AWS account. To run this example you're going to need following accesses:\n",
    "- AmazonEC2ContainerRegistryFullAccess\n",
    "- AmazonEC2FullAccess\n",
    "- AmazonS3FullAccess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdbd705",
   "metadata": {},
   "source": [
    "**Define also following variables.** These variables are needed for the Deep Learning containers to build the Docker and push it to the AWS ECR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f88da73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-03-08-14-05-25'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "current_datetime = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "current_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "720fbaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCOUNT_ID = \"\"\n",
    "REPOSITORY_NAME = \"pytorch_inference\"\n",
    "REGION = \"us-west-2\"\n",
    "# modify this based on your S3 Bucket name\n",
    "S3_BUCKET_NAME = \"\" # s3://<s3 bucket name>/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d41e8e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'205130860845.dkr.ecr.us-west-2.amazonaws.com/pytorch_inference:2.2.0-cpu-intel-py310-ubuntu20.04-sagemaker-codegen-2024-03-08-14-05-25'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define these variable names based on S3 Bucket name and ECR url\n",
    "import os\n",
    "tag = f\"2.2.0-cpu-intel-py310-ubuntu20.04-sagemaker-codegen-{current_datetime}\"\n",
    "ECR_URL = f\"{ACCOUNT_ID}.dkr.ecr.{REGION}.amazonaws.com/{REPOSITORY_NAME}:{tag}\"\n",
    "S3_URL = os.path.join(S3_BUCKET_NAME, \"codegen25.tar.gz\")\n",
    "endpoint_name = \"codegen-ipex\"\n",
    "ECR_URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a092c8",
   "metadata": {},
   "source": [
    "### Build Deep Learning Container and push it to AWS ECR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952893b3",
   "metadata": {},
   "source": [
    "If you don't have Docker image prepared beforehand, build the image with all required intel optimizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6eece85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARG PYTHON=python3\r\n",
      "ARG PYTHON_VERSION=3.10.13\r\n",
      "ARG MINIFORGE3_VERSION=23.11.0-0\r\n",
      "\r\n",
      "FROM ubuntu:20.04 AS sagemaker\r\n",
      "\r\n",
      "LABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\r\n",
      "LABEL com.amazonaws.sagemaker.capabilities.multi-models=true\r\n",
      "\r\n",
      "ARG PYTHON\r\n",
      "ARG PYTHON_VERSION\r\n",
      "ARG MINIFORGE3_VERSION\r\n",
      "\r\n",
      "ENV TORCHSERVE_VERSION=\"0.8.2\"\r\n",
      "ENV SM_TOOLKIT_VERSION=\"2.0.22\"\r\n",
      "ENV SAGEMAKER_SERVING_MODULE sagemaker_pytorch_serving_container.serving:main\r\n",
      "\r\n",
      "# Set Env Variables for the images\r\n",
      "ENV DEBIAN_FRONTEND=noninteractive\r\n",
      "ENV LD_LIBRARY_PATH=\"${LD_LIBRARY_PATH}:/usr/local/lib\"\r\n",
      "ENV LD_LIBRARY_PATH=\"/opt/conda/lib:${LD_LIBRARY_PATH}\"\r\n",
      "ENV PYTHONIOENCODING=UTF-8\r\n",
      "# See http://bugs.python.org/issue19846\r\n",
      "ENV LANG=C.UTF-8\r\n",
      "ENV PATH=/opt/conda/bin:$PATH\r\n",
      "ENV TEMP=/home/model-server/tmp\r\n",
      "ENV MKL_THREADING_LAYER=GNU\r\n",
      "\r\n",
      "ENV DLC_CONTAINER_TYPE=inference\r\n",
      "\r\n",
      "RUN apt-get -y update \\\r\n",
      " && apt-get -y upgrade \\\r\n",
      " && apt-get install -y --no-install-recommends \\\r\n",
      "    build-essential \\\r\n",
      "    ca-certificates \\\r\n",
      "    cmake \\\r\n",
      "    curl \\\r\n",
      "    emacs \\\r\n",
      "    git \\\r\n",
      "    jq \\\r\n",
      "    libcurl4-openssl-dev \\\r\n",
      "    libgl1-mesa-glx \\\r\n",
      "    libglib2.0-0 \\\r\n",
      "    libjemalloc-dev \\\r\n",
      "    google-perftools \\\r\n",
      "    libsm6 \\\r\n",
      "    libssl-dev \\\r\n",
      "    libxext6 \\\r\n",
      "    libxrender-dev \\\r\n",
      "    numactl \\\r\n",
      "    openjdk-17-jdk \\\r\n",
      "    openssl \\\r\n",
      "    unzip \\\r\n",
      "    vim \\\r\n",
      "    wget \\\r\n",
      "    libjpeg-dev \\\r\n",
      "    libpng-dev \\\r\n",
      "    zlib1g-dev \\\r\n",
      " && apt-get autoremove -y \\\r\n",
      " && rm -rf /var/lib/apt/lists/* \\\r\n",
      " && apt-get clean\r\n",
      "\r\n",
      "# Install CondaForge miniconda\r\n",
      "RUN curl -L -o ~/miniforge3.sh https://github.com/conda-forge/miniforge/releases/download/${MINIFORGE3_VERSION}/Miniforge3-${MINIFORGE3_VERSION}-Linux-x86_64.sh \\\r\n",
      " && chmod +x ~/miniforge3.sh \\\r\n",
      " && ~/miniforge3.sh -b -p /opt/conda \\\r\n",
      " && rm ~/miniforge3.sh \\\r\n",
      " && /opt/conda/bin/conda install -c conda-forge \\\r\n",
      "    python=${PYTHON_VERSION} \\\r\n",
      "    cython \\\r\n",
      "    \"mkl>=2023.2.0\" \\\r\n",
      "    mkl-include \\\r\n",
      "    parso \\\r\n",
      "    \"scipy==1.10.1\" \\\r\n",
      "    typing \\\r\n",
      "    h5py \\\r\n",
      "    requests \\\r\n",
      "    libgcc \\\r\n",
      "    cmake \\\r\n",
      "    packaging \\\r\n",
      "    awscli \\\r\n",
      "    \"boto3==1.28.60\" \\\r\n",
      "    pyyaml \\\r\n",
      "    packaging \\\r\n",
      "    conda-content-trust \\\r\n",
      "    charset-normalizer \\\r\n",
      "    scikit-learn \\\r\n",
      "    pandas \\\r\n",
      "    \"numpy==1.24.4\" \\\r\n",
      "    botocore \\\r\n",
      "    s3transfer || true \\\r\n",
      " && /opt/conda/bin/conda clean -afy \\\r\n",
      " && rm -rf /etc/apt/sources.list.d/*\r\n",
      "\r\n",
      "# symlink pip for OS use\r\n",
      "RUN pip install --upgrade pip --trusted-host pypi.org --trusted-host files.pythonhosted.org \\\r\n",
      " && ln -s /opt/conda/bin/pip /usr/local/bin/pip3\r\n",
      "\r\n",
      "RUN pip install --no-cache-dir sagemaker-pytorch-inference==${SM_TOOLKIT_VERSION}\r\n",
      "\r\n",
      "# Install Common python packages\r\n",
      "RUN pip install --no-cache-dir --extra-index-url https://download.pytorch.org/whl/cpu -U \\\r\n",
      "    opencv-python \\\r\n",
      "    pyopenssl \\\r\n",
      "    \"cryptography>41.0.6\" \\\r\n",
      "    \"ipython>=8.10.0,<9.0\" \\\r\n",
      "    \"urllib3>=1.26.18,<2\" \\\r\n",
      "    \"prompt-toolkit<3.0.39\"\r\n",
      "\r\n",
      "# Install Pytorch\r\n",
      "RUN pip install --no-cache-dir -U torch==2.2 torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\r\n",
      "\r\n",
      "# Install Intel® Extension for PyTorch*\r\n",
      "RUN pip install --no-cache-dir -U \\\r\n",
      "    intel-openmp \\\r\n",
      "    intel-extension-for-pytorch==2.2.0\r\n",
      "\r\n",
      "RUN python -m pip install oneccl_bind_pt --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/cpu/us/\r\n",
      "\r\n",
      "RUN pip install --no-cache-dir -U \\\r\n",
      "    transformers==4.33.2 \\\r\n",
      "    diffusers \\\r\n",
      "    accelerate \\\r\n",
      "    tiktoken\r\n",
      "\r\n",
      "# Install TorchServe pypi dependencies directly from their requirements.txt file\r\n",
      "# NOTE: This also brings in unnecessary cpu dependencies like nvgpu\r\n",
      "RUN pip install --no-cache-dir -U -r https://raw.githubusercontent.com/pytorch/serve/v${TORCHSERVE_VERSION}/requirements/common.txt \\\r\n",
      " && pip install --no-cache-dir -U \\\r\n",
      "    torchserve==${TORCHSERVE_VERSION} \\\r\n",
      "    torch-model-archiver==${TORCHSERVE_VERSION}\r\n",
      "\r\n",
      "# create user and folders\r\n",
      "RUN useradd -m model-server \\\r\n",
      " && mkdir -p /home/model-server/tmp /opt/ml/model \\\r\n",
      " && chown -R model-server /home/model-server /opt/ml/model\r\n",
      "\r\n",
      "# add TS entrypoint\r\n",
      "COPY torchserve-entrypoint.py /usr/local/bin/dockerd-entrypoint.py\r\n",
      "COPY config.properties /home/model-server\r\n",
      "RUN chmod +x /usr/local/bin/dockerd-entrypoint.py\r\n",
      "\r\n",
      "RUN HOME_DIR=/root \\\r\n",
      " && curl -o ${HOME_DIR}/oss_compliance.zip https://aws-dlinfra-utilities.s3.amazonaws.com/oss_compliance.zip \\\r\n",
      " && unzip ${HOME_DIR}/oss_compliance.zip -d ${HOME_DIR}/ \\\r\n",
      " && cp ${HOME_DIR}/oss_compliance/test/testOSSCompliance /usr/local/bin/testOSSCompliance \\\r\n",
      " && chmod +x /usr/local/bin/testOSSCompliance \\\r\n",
      " && chmod +x ${HOME_DIR}/oss_compliance/generate_oss_compliance.sh \\\r\n",
      " && ${HOME_DIR}/oss_compliance/generate_oss_compliance.sh ${HOME_DIR} ${PYTHON} \\\r\n",
      " && rm -rf ${HOME_DIR}/oss_compliance*\r\n",
      "\r\n",
      "## Cleanup ##\r\n",
      "RUN pip cache purge \\\r\n",
      " && rm -rf /tmp/tmp* \\\r\n",
      " && rm -iRf /root/.cache\r\n",
      "\r\n",
      "# INTEL specific ENVs\r\n",
      "ENV KMP_SETTINGS=1\r\n",
      "ENV LD_PRELOAD=\"/usr/lib/x86_64-linux-gnu/libjemalloc.so:/opt/conda/lib/libiomp5.so:${LD_PRELOAD}\"\r\n",
      "\r\n",
      "EXPOSE 8080 8081\r\n",
      "ENTRYPOINT [\"python\", \"/usr/local/bin/dockerd-entrypoint.py\"]\r\n",
      "CMD [\"torchserve\", \"--start\", \"--ts-config\", \"/home/model-server/config.properties\", \"--model-store\", \"/home/model-server/\"]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# review Docker\n",
    "!cat docker/Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "443d97b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  9.216kB\n",
      "Step 1/42 : ARG PYTHON=python3\n",
      "Step 2/42 : ARG PYTHON_VERSION=3.10.13\n",
      "Step 3/42 : ARG MINIFORGE3_VERSION=23.11.0-0\n",
      "Step 4/42 : FROM ubuntu:20.04 AS sagemaker\n",
      " ---> 3cff1c6ff37e\n",
      "Step 5/42 : LABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\n",
      " ---> Using cache\n",
      " ---> 37386c6722a6\n",
      "Step 6/42 : LABEL com.amazonaws.sagemaker.capabilities.multi-models=true\n",
      " ---> Using cache\n",
      " ---> dbb0b22555ff\n",
      "Step 7/42 : ARG PYTHON\n",
      " ---> Using cache\n",
      " ---> d653f71c2132\n",
      "Step 8/42 : ARG PYTHON_VERSION\n",
      " ---> Using cache\n",
      " ---> 606b73eaefda\n",
      "Step 9/42 : ARG MINIFORGE3_VERSION\n",
      " ---> Using cache\n",
      " ---> 47b945f0abbb\n",
      "Step 10/42 : ENV TORCHSERVE_VERSION=\"0.8.2\"\n",
      " ---> Using cache\n",
      " ---> 2e3bf6056a8b\n",
      "Step 11/42 : ENV SM_TOOLKIT_VERSION=\"2.0.22\"\n",
      " ---> Using cache\n",
      " ---> 0bb5c0bae7b7\n",
      "Step 12/42 : ENV SAGEMAKER_SERVING_MODULE sagemaker_pytorch_serving_container.serving:main\n",
      " ---> Using cache\n",
      " ---> 14721f4f33a8\n",
      "Step 13/42 : ENV DEBIAN_FRONTEND=noninteractive\n",
      " ---> Using cache\n",
      " ---> 0264859b8650\n",
      "Step 14/42 : ENV LD_LIBRARY_PATH=\"${LD_LIBRARY_PATH}:/usr/local/lib\"\n",
      " ---> Using cache\n",
      " ---> 7f5517e10caf\n",
      "Step 15/42 : ENV LD_LIBRARY_PATH=\"/opt/conda/lib:${LD_LIBRARY_PATH}\"\n",
      " ---> Using cache\n",
      " ---> 372997db6375\n",
      "Step 16/42 : ENV PYTHONIOENCODING=UTF-8\n",
      " ---> Using cache\n",
      " ---> ad6ad05d3f57\n",
      "Step 17/42 : ENV LANG=C.UTF-8\n",
      " ---> Using cache\n",
      " ---> 012e5c329efd\n",
      "Step 18/42 : ENV PATH=/opt/conda/bin:$PATH\n",
      " ---> Using cache\n",
      " ---> 539dac0d8010\n",
      "Step 19/42 : ENV TEMP=/home/model-server/tmp\n",
      " ---> Using cache\n",
      " ---> 64ee0ca2b362\n",
      "Step 20/42 : ENV MKL_THREADING_LAYER=GNU\n",
      " ---> Using cache\n",
      " ---> 35c3bc0e6dcd\n",
      "Step 21/42 : ENV DLC_CONTAINER_TYPE=inference\n",
      " ---> Using cache\n",
      " ---> 497cc42fa968\n",
      "Step 22/42 : RUN apt-get -y update  && apt-get -y upgrade  && apt-get install -y --no-install-recommends     build-essential     ca-certificates     cmake     curl     emacs     git     jq     libcurl4-openssl-dev     libgl1-mesa-glx     libglib2.0-0     libjemalloc-dev     google-perftools     libsm6     libssl-dev     libxext6     libxrender-dev     numactl     openjdk-17-jdk     openssl     unzip     vim     wget     libjpeg-dev     libpng-dev     zlib1g-dev  && apt-get autoremove -y  && rm -rf /var/lib/apt/lists/*  && apt-get clean\n",
      " ---> Using cache\n",
      " ---> d13abda787df\n",
      "Step 23/42 : RUN curl -L -o ~/miniforge3.sh https://github.com/conda-forge/miniforge/releases/download/${MINIFORGE3_VERSION}/Miniforge3-${MINIFORGE3_VERSION}-Linux-x86_64.sh  && chmod +x ~/miniforge3.sh  && ~/miniforge3.sh -b -p /opt/conda  && rm ~/miniforge3.sh  && /opt/conda/bin/conda install -c conda-forge     python=${PYTHON_VERSION}     cython     \"mkl>=2023.2.0\"     mkl-include     parso     \"scipy==1.10.1\"     typing     h5py     requests     libgcc     cmake     packaging     awscli     \"boto3==1.28.60\"     pyyaml     packaging     conda-content-trust     charset-normalizer     scikit-learn     pandas     \"numpy==1.24.4\"     botocore     s3transfer || true  && /opt/conda/bin/conda clean -afy  && rm -rf /etc/apt/sources.list.d/*\n",
      " ---> Using cache\n",
      " ---> 2fecc70174b1\n",
      "Step 24/42 : RUN pip install --upgrade pip --trusted-host pypi.org --trusted-host files.pythonhosted.org  && ln -s /opt/conda/bin/pip /usr/local/bin/pip3\n",
      " ---> Using cache\n",
      " ---> 5fbeb4c74acf\n",
      "Step 25/42 : RUN pip install --no-cache-dir sagemaker-pytorch-inference==${SM_TOOLKIT_VERSION}\n",
      " ---> Running in 8f78913418f8\n",
      "Collecting sagemaker-pytorch-inference==2.0.22\n",
      "  Downloading sagemaker_pytorch_inference-2.0.22.tar.gz (22 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting boto3>=1.28.60 (from sagemaker-pytorch-inference==2.0.22)\n",
      "  Downloading boto3-1.34.58-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting numpy>=1.24.4 (from sagemaker-pytorch-inference==2.0.22)\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.0/61.0 kB 4.7 MB/s eta 0:00:00\n",
      "Collecting six>=1.16.0 (from sagemaker-pytorch-inference==2.0.22)\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting retrying>=1.3.4 (from sagemaker-pytorch-inference==2.0.22)\n",
      "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting scipy>=1.10.1 (from sagemaker-pytorch-inference==2.0.22)\n",
      "  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.4/60.4 kB 124.5 MB/s eta 0:00:00\n",
      "Collecting psutil>=5.9.5 (from sagemaker-pytorch-inference==2.0.22)\n",
      "  Downloading psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Collecting botocore<1.35.0,>=1.34.58 (from boto3>=1.28.60->sagemaker-pytorch-inference==2.0.22)\n",
      "  Downloading botocore-1.34.58-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.28.60->sagemaker-pytorch-inference==2.0.22)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3>=1.28.60->sagemaker-pytorch-inference==2.0.22)\n",
      "  Downloading s3transfer-0.10.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting python-dateutil<3.0.0,>=2.1 (from botocore<1.35.0,>=1.34.58->boto3>=1.28.60->sagemaker-pytorch-inference==2.0.22)\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<2.1,>=1.25.4 (from botocore<1.35.0,>=1.34.58->boto3>=1.28.60->sagemaker-pytorch-inference==2.0.22)\n",
      "  Downloading urllib3-2.0.7-py3-none-any.whl.metadata (6.6 kB)\n",
      "Downloading boto3-1.34.58-py3-none-any.whl (139 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 139.3/139.3 kB 110.3 MB/s eta 0:00:00\n",
      "Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.2/18.2 MB 150.6 MB/s eta 0:00:00\n",
      "Downloading psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 288.2/288.2 kB 370.1 MB/s eta 0:00:00\n",
      "Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
      "Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 38.4/38.4 MB 286.5 MB/s eta 0:00:00\n",
      "Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading botocore-1.34.58-py3-none-any.whl (12.0 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.0/12.0 MB 265.6 MB/s eta 0:00:00\n",
      "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading s3transfer-0.10.0-py3-none-any.whl (82 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 82.1/82.1 kB 210.9 MB/s eta 0:00:00\n",
      "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 229.9/229.9 kB 368.8 MB/s eta 0:00:00\n",
      "Downloading urllib3-2.0.7-py3-none-any.whl (124 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 124.2/124.2 kB 274.7 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: sagemaker-pytorch-inference\n",
      "  Building wheel for sagemaker-pytorch-inference (setup.py): started\n",
      "  Building wheel for sagemaker-pytorch-inference (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker-pytorch-inference: filename=sagemaker_pytorch_inference-2.0.22-py2.py3-none-any.whl size=35876 sha256=f0175481d789e18d8cf2ab2d86812d25950a7107d0ef20b95f40343245180045\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-wf7mq_zy/wheels/02/2b/c8/7e6a859668906fe1ef25a7290ddb61503e354ab6dc5995110f\n",
      "Successfully built sagemaker-pytorch-inference\n",
      "Installing collected packages: urllib3, six, psutil, numpy, jmespath, scipy, retrying, python-dateutil, botocore, s3transfer, boto3, sagemaker-pytorch-inference\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.1.0\n",
      "    Uninstalling urllib3-2.1.0:\n",
      "      Successfully uninstalled urllib3-2.1.0\n",
      "Successfully installed boto3-1.34.58 botocore-1.34.58 jmespath-1.0.1 numpy-1.26.4 psutil-5.9.8 python-dateutil-2.9.0.post0 retrying-1.3.4 s3transfer-0.10.0 sagemaker-pytorch-inference-2.0.22 scipy-1.12.0 six-1.16.0 urllib3-2.0.7\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mRemoving intermediate container 8f78913418f8\n",
      " ---> 40ae302009e6\n",
      "Step 26/42 : RUN pip install --no-cache-dir --extra-index-url https://download.pytorch.org/whl/cpu -U     opencv-python     pyopenssl     \"cryptography>41.0.6\"     \"ipython>=8.10.0,<9.0\"     \"urllib3>=1.26.18,<2\"     \"prompt-toolkit<3.0.39\"\n",
      " ---> Running in cbb4f8a176f9\n",
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting pyopenssl\n",
      "  Downloading pyOpenSSL-24.0.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting cryptography>41.0.6\n",
      "  Downloading cryptography-42.0.5-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting ipython<9.0,>=8.10.0\n",
      "  Downloading ipython-8.22.2-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting urllib3<2,>=1.26.18\n",
      "  Downloading urllib3-1.26.18-py2.py3-none-any.whl.metadata (48 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.9/48.9 kB 8.0 MB/s eta 0:00:00\n",
      "Collecting prompt-toolkit<3.0.39\n",
      "  Downloading prompt_toolkit-3.0.38-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>41.0.6) (1.16.0)\n",
      "Collecting decorator (from ipython<9.0,>=8.10.0)\n",
      "  Downloading decorator-5.1.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting jedi>=0.16 (from ipython<9.0,>=8.10.0)\n",
      "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting matplotlib-inline (from ipython<9.0,>=8.10.0)\n",
      "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl.metadata (2.8 kB)\n",
      "INFO: pip is looking at multiple versions of ipython to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting ipython<9.0,>=8.10.0\n",
      "  Downloading ipython-8.22.1-py3-none-any.whl.metadata (4.8 kB)\n",
      "  Downloading ipython-8.21.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading ipython-8.20.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading ipython-8.18.1-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading ipython-8.18.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting pygments>=2.4.0 (from ipython<9.0,>=8.10.0)\n",
      "  Downloading pygments-2.17.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting stack-data (from ipython<9.0,>=8.10.0)\n",
      "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting traitlets>=5 (from ipython<9.0,>=8.10.0)\n",
      "  Downloading traitlets-5.14.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting exceptiongroup (from ipython<9.0,>=8.10.0)\n",
      "  Downloading exceptiongroup-1.2.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting pexpect>4.3 (from ipython<9.0,>=8.10.0)\n",
      "  Downloading pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting wcwidth (from prompt-toolkit<3.0.39)\n",
      "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>41.0.6) (2.21)\n",
      "Collecting parso<0.9.0,>=0.8.3 (from jedi>=0.16->ipython<9.0,>=8.10.0)\n",
      "  Downloading parso-0.8.3-py2.py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting ptyprocess>=0.5 (from pexpect>4.3->ipython<9.0,>=8.10.0)\n",
      "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting executing>=1.2.0 (from stack-data->ipython<9.0,>=8.10.0)\n",
      "  Downloading executing-2.0.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting asttokens>=2.1.0 (from stack-data->ipython<9.0,>=8.10.0)\n",
      "  Downloading asttokens-2.4.1-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting pure-eval (from stack-data->ipython<9.0,>=8.10.0)\n",
      "  Downloading pure_eval-0.2.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython<9.0,>=8.10.0) (1.16.0)\n",
      "Downloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.2 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.2/62.2 MB 267.9 MB/s eta 0:00:00\n",
      "Downloading pyOpenSSL-24.0.0-py3-none-any.whl (58 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.6/58.6 kB 261.1 MB/s eta 0:00:00\n",
      "Downloading cryptography-42.0.5-cp39-abi3-manylinux_2_28_x86_64.whl (4.6 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.6/4.6 MB 206.6 MB/s eta 0:00:00\n",
      "Downloading ipython-8.18.0-py3-none-any.whl (808 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 808.2/808.2 kB 222.6 MB/s eta 0:00:00\n",
      "Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 143.8/143.8 kB 342.1 MB/s eta 0:00:00\n",
      "Downloading prompt_toolkit-3.0.38-py3-none-any.whl (385 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 385.8/385.8 kB 377.2 MB/s eta 0:00:00\n",
      "Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 332.3 MB/s eta 0:00:00\n",
      "Downloading pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 63.8/63.8 kB 263.1 MB/s eta 0:00:00\n",
      "Downloading pygments-2.17.2-py3-none-any.whl (1.2 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 393.3 MB/s eta 0:00:00\n",
      "Downloading traitlets-5.14.1-py3-none-any.whl (85 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.4/85.4 kB 297.8 MB/s eta 0:00:00\n",
      "Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
      "Downloading exceptiongroup-1.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
      "Downloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
      "Downloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
      "Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
      "Downloading executing-2.0.1-py2.py3-none-any.whl (24 kB)\n",
      "Downloading parso-0.8.3-py2.py3-none-any.whl (100 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100.8/100.8 kB 309.4 MB/s eta 0:00:00\n",
      "Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
      "Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: wcwidth, pure-eval, ptyprocess, urllib3, traitlets, pygments, prompt-toolkit, pexpect, parso, opencv-python, executing, exceptiongroup, decorator, asttokens, stack-data, matplotlib-inline, jedi, cryptography, pyopenssl, ipython\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.0.7\n",
      "    Uninstalling urllib3-2.0.7:\n",
      "      Successfully uninstalled urllib3-2.0.7\n",
      "Successfully installed asttokens-2.4.1 cryptography-42.0.5 decorator-5.1.1 exceptiongroup-1.2.0 executing-2.0.1 ipython-8.18.0 jedi-0.19.1 matplotlib-inline-0.1.6 opencv-python-4.9.0.80 parso-0.8.3 pexpect-4.9.0 prompt-toolkit-3.0.38 ptyprocess-0.7.0 pure-eval-0.2.2 pygments-2.17.2 pyopenssl-24.0.0 stack-data-0.6.3 traitlets-5.14.1 urllib3-1.26.18 wcwidth-0.2.13\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container cbb4f8a176f9\n",
      " ---> 4419624f03be\n",
      "Step 27/42 : RUN pip install --no-cache-dir -U torch==2.2 torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
      " ---> Running in 4cf6ef591529\n",
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Collecting torch==2.2\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-2.2.0%2Bcpu-cp310-cp310-linux_x86_64.whl (186.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 186.7/186.7 MB 234.3 MB/s eta 0:00:00\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.17.1%2Bcpu-cp310-cp310-linux_x86_64.whl (1.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 296.5 MB/s eta 0:00:00\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.2.1%2Bcpu-cp310-cp310-linux_x86_64.whl (1.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 271.5 MB/s eta 0:00:00\n",
      "Collecting filelock (from torch==2.2)\n",
      "  Downloading https://download.pytorch.org/whl/filelock-3.9.0-py3-none-any.whl (9.7 kB)\n",
      "Collecting typing-extensions>=4.8.0 (from torch==2.2)\n",
      "  Downloading https://download.pytorch.org/whl/typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Collecting sympy (from torch==2.2)\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.12-py3-none-any.whl (5.7 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 243.5 MB/s eta 0:00:00\n",
      "Collecting networkx (from torch==2.2)\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 228.2 MB/s eta 0:00:00\n",
      "Collecting jinja2 (from torch==2.2)\n",
      "  Downloading https://download.pytorch.org/whl/Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 133.1/133.1 kB 200.6 MB/s eta 0:00:00\n",
      "Collecting fsspec (from torch==2.2)\n",
      "  Downloading https://download.pytorch.org/whl/fsspec-2023.4.0-py3-none-any.whl (153 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 154.0/154.0 kB 325.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.17.0%2Bcpu-cp310-cp310-linux_x86_64.whl (1.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 310.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Downloading https://download.pytorch.org/whl/pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 240.6 MB/s eta 0:00:00\n",
      "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.2.0%2Bcpu-cp310-cp310-linux_x86_64.whl (1.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 198.2 MB/s eta 0:00:00\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.2)\n",
      "  Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2023.11.17)\n",
      "Collecting mpmath>=0.19 (from sympy->torch==2.2)\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 536.2/536.2 kB 330.0 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, typing-extensions, sympy, pillow, networkx, MarkupSafe, fsspec, filelock, jinja2, torch, torchvision, torchaudio\n",
      "Successfully installed MarkupSafe-2.1.3 filelock-3.9.0 fsspec-2023.4.0 jinja2-3.1.2 mpmath-1.3.0 networkx-3.2.1 pillow-10.2.0 sympy-1.12 torch-2.2.0+cpu torchaudio-2.2.0+cpu torchvision-0.17.0+cpu typing-extensions-4.8.0\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container 4cf6ef591529\n",
      " ---> 7b45fbc5c60b\n",
      "Step 28/42 : RUN pip install --no-cache-dir -U     intel-openmp     intel-extension-for-pytorch==2.2.0\n",
      " ---> Running in 62b8028ec2b1\n",
      "Collecting intel-openmp\n",
      "  Downloading intel_openmp-2024.0.2-py2.py3-none-manylinux1_x86_64.whl.metadata (1.2 kB)\n",
      "Collecting intel-extension-for-pytorch==2.2.0\n",
      "  Downloading intel_extension_for_pytorch-2.2.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from intel-extension-for-pytorch==2.2.0) (5.9.8)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from intel-extension-for-pytorch==2.2.0) (1.26.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from intel-extension-for-pytorch==2.2.0) (23.2)\n",
      "Downloading intel_extension_for_pytorch-2.2.0-cp310-cp310-manylinux2014_x86_64.whl (52.7 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.7/52.7 MB 183.8 MB/s eta 0:00:00\n",
      "Downloading intel_openmp-2024.0.2-py2.py3-none-manylinux1_x86_64.whl (28.6 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 28.6/28.6 MB 195.5 MB/s eta 0:00:00\n",
      "Installing collected packages: intel-openmp, intel-extension-for-pytorch\n",
      "Successfully installed intel-extension-for-pytorch-2.2.0 intel-openmp-2024.0.2\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container 62b8028ec2b1\n",
      " ---> 83346b08f7a3\n",
      "Step 29/42 : RUN python -m pip install oneccl_bind_pt --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/cpu/us/\n",
      " ---> Running in 057fc19feebf\n",
      "Looking in indexes: https://pypi.org/simple, https://pytorch-extension.intel.com/release-whl/stable/cpu/us/\n",
      "Collecting oneccl_bind_pt\n",
      "  Downloading https://intel-extension-for-pytorch.s3.amazonaws.com/ipex_stable/cpu/./oneccl_bind_pt-2.2.0%2Bcpu-cp310-cp310-linux_x86_64.whl (39.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 39.8/39.8 MB 24.9 MB/s eta 0:00:00\n",
      "Installing collected packages: oneccl_bind_pt\n",
      "Successfully installed oneccl_bind_pt-2.2.0+cpu\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container 057fc19feebf\n",
      " ---> 3e7470df796a\n",
      "Step 30/42 : RUN pip install --no-cache-dir -U     transformers==4.33.2     diffusers     accelerate     tiktoken\n",
      " ---> Running in 2106f89012ed\n",
      "Collecting transformers==4.33.2\n",
      "  Downloading transformers-4.33.2-py3-none-any.whl.metadata (119 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 119.9/119.9 kB 6.5 MB/s eta 0:00:00\n",
      "Collecting diffusers\n",
      "  Downloading diffusers-0.26.3-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.27.2-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.2) (3.9.0)\n",
      "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers==4.33.2)\n",
      "  Downloading huggingface_hub-0.21.4-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.2) (23.2)\n",
      "Collecting pyyaml>=5.1 (from transformers==4.33.2)\n",
      "  Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.33.2)\n",
      "  Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.9/40.9 kB 226.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.2) (2.31.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.33.2)\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers==4.33.2)\n",
      "  Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.2) (4.66.1)\n",
      "Collecting importlib-metadata (from diffusers)\n",
      "  Downloading importlib_metadata-7.0.2-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from diffusers) (10.2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.2.0+cpu)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.2)\n",
      "  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.2) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.2) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.2) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.2) (2023.11.17)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Collecting zipp>=0.5 (from importlib-metadata->diffusers)\n",
      "  Downloading zipp-3.17.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading transformers-4.33.2-py3-none-any.whl (7.6 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.6/7.6 MB 132.4 MB/s eta 0:00:00\n",
      "Downloading diffusers-0.26.3-py3-none-any.whl (1.9 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.9/1.9 MB 330.2 MB/s eta 0:00:00\n",
      "Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 280.0/280.0 kB 364.1 MB/s eta 0:00:00\n",
      "Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.8/1.8 MB 341.2 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.21.4-py3-none-any.whl (346 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 346.4/346.4 kB 366.7 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 705.5/705.5 kB 391.7 MB/s eta 0:00:00\n",
      "Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 774.0/774.0 kB 386.6 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 385.9 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.8/7.8 MB 272.8 MB/s eta 0:00:00\n",
      "Downloading importlib_metadata-7.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 170.9/170.9 kB 339.6 MB/s eta 0:00:00\n",
      "Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB)\n",
      "Installing collected packages: tokenizers, zipp, safetensors, regex, pyyaml, fsspec, tiktoken, importlib-metadata, huggingface-hub, transformers, diffusers, accelerate\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "Successfully installed accelerate-0.27.2 diffusers-0.26.3 fsspec-2024.2.0 huggingface-hub-0.21.4 importlib-metadata-7.0.2 pyyaml-6.0.1 regex-2023.12.25 safetensors-0.4.2 tiktoken-0.6.0 tokenizers-0.13.3 transformers-4.33.2 zipp-3.17.0\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container 2106f89012ed\n",
      " ---> 6c77d3e79421\n",
      "Step 31/42 : RUN pip install --no-cache-dir -U -r https://raw.githubusercontent.com/pytorch/serve/v${TORCHSERVE_VERSION}/requirements/common.txt  && pip install --no-cache-dir -U     torchserve==${TORCHSERVE_VERSION}     torch-model-archiver==${TORCHSERVE_VERSION}\n",
      " ---> Running in d33a110aa968\n",
      "Collecting psutil==5.9.5 (from -r https://raw.githubusercontent.com/pytorch/serve/v0.8.2/requirements/common.txt (line 1))\n",
      "  Downloading psutil-5.9.5-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: requests==2.31.0 in /opt/conda/lib/python3.10/site-packages (from -r https://raw.githubusercontent.com/pytorch/serve/v0.8.2/requirements/common.txt (line 2)) (2.31.0)\n",
      "Collecting captum==0.6.0 (from -r https://raw.githubusercontent.com/pytorch/serve/v0.8.2/requirements/common.txt (line 3))\n",
      "  Downloading captum-0.6.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting packaging==23.1 (from -r https://raw.githubusercontent.com/pytorch/serve/v0.8.2/requirements/common.txt (line 4))\n",
      "  Downloading packaging-23.1-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting pynvml==11.4.1 (from -r https://raw.githubusercontent.com/pytorch/serve/v0.8.2/requirements/common.txt (line 5))\n",
      "  Downloading pynvml-11.4.1-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting pyyaml==6.0 (from -r https://raw.githubusercontent.com/pytorch/serve/v0.8.2/requirements/common.txt (line 6))\n",
      "  Downloading PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests==2.31.0->-r https://raw.githubusercontent.com/pytorch/serve/v0.8.2/requirements/common.txt (line 2)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests==2.31.0->-r https://raw.githubusercontent.com/pytorch/serve/v0.8.2/requirements/common.txt (line 2)) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests==2.31.0->-r https://raw.githubusercontent.com/pytorch/serve/v0.8.2/requirements/common.txt (line 2)) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests==2.31.0->-r https://raw.githubusercontent.com/pytorch/serve/v0.8.2/requirements/common.txt (line 2)) (2023.11.17)\n",
      "Collecting matplotlib (from captum==0.6.0->-r https://raw.githubusercontent.com/pytorch/serve/v0.8.2/requirements/common.txt (line 3))\n",
      "  Downloading matplotlib-3.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from captum==0.6.0->-r https://raw.githubusercontent.com/pytorch/serve/v0.8.2/requirements/common.txt (line 3)) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.6 in /opt/conda/lib/python3.10/site-packages (from captum==0.6.0->-r https://raw.githubusercontent.com/pytorch/serve/v0.8.2/requirements/common.txt (line 3)) (2.2.0+cpu)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum==0.6.0->-r https://raw.githubusercontent.com/pytorch/serve/v0.8.2/requirements/common.txt (line 3)) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum==0.6.0->-r https://raw.githubusercontent.com/pytorch/serve/v0.8.2/requirements/common.txt (line 3)) (4.8.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum==0.6.0->-r https://raw.githubusercontent.com/pytorch/serve/v0.8.2/requirements/common.txt (line 3)) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum==0.6.0->-r https://raw.githubusercontent.com/pytorch/serve/v0.8.2/requirements/common.txt (line 3)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum==0.6.0->-r https://raw.githubusercontent.com/pytorch/serve/v0.8.2/requirements/common.txt (line 3)) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum==0.6.0->-r https://raw.githubusercontent.com/pytorch/serve/v0.8.2/requirements/common.txt (line 3)) (2024.2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting contourpy>=1.0.1 (from matplotlib->captum==0.6.0->-r https://raw.githubusercontent.com/pytorch/serve/v0.8.2/requirements/common.txt (line 3))\n",
      "  Downloading contourpy-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->captum==0.6.0->-r https://raw.githubusercontent.com/pytorch/serve/v0.8.2/requirements/common.txt (line 3))\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->captum==0.6.0->-r https://raw.githubusercontent.com/pytorch/serve/v0.8.2/requirements/common.txt (line 3))\n",
      "  Downloading fonttools-4.49.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (159 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 159.1/159.1 kB 17.0 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->captum==0.6.0->-r https://raw.githubusercontent.com/pytorch/serve/v0.8.2/requirements/common.txt (line 3))\n",
      "  Downloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum==0.6.0->-r https://raw.githubusercontent.com/pytorch/serve/v0.8.2/requirements/common.txt (line 3)) (10.2.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->captum==0.6.0->-r https://raw.githubusercontent.com/pytorch/serve/v0.8.2/requirements/common.txt (line 3))\n",
      "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum==0.6.0->-r https://raw.githubusercontent.com/pytorch/serve/v0.8.2/requirements/common.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->captum==0.6.0->-r https://raw.githubusercontent.com/pytorch/serve/v0.8.2/requirements/common.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6->captum==0.6.0->-r https://raw.githubusercontent.com/pytorch/serve/v0.8.2/requirements/common.txt (line 3)) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6->captum==0.6.0->-r https://raw.githubusercontent.com/pytorch/serve/v0.8.2/requirements/common.txt (line 3)) (1.3.0)\n",
      "Downloading psutil-5.9.5-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (282 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 282.1/282.1 kB 53.0 MB/s eta 0:00:00\n",
      "Downloading captum-0.6.0-py3-none-any.whl (1.3 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 146.2 MB/s eta 0:00:00\n",
      "Downloading packaging-23.1-py3-none-any.whl (48 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.9/48.9 kB 171.5 MB/s eta 0:00:00\n",
      "Downloading pynvml-11.4.1-py3-none-any.whl (46 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 47.0/47.0 kB 175.1 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (682 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 682.2/682.2 kB 354.7 MB/s eta 0:00:00\n",
      "Downloading matplotlib-3.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.6/11.6 MB 227.6 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (310 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 310.7/310.7 kB 365.4 MB/s eta 0:00:00\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.49.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.6/4.6 MB 283.9 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 316.4 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 103.2/103.2 kB 304.2 MB/s eta 0:00:00\n",
      "Installing collected packages: pyyaml, pyparsing, pynvml, psutil, packaging, kiwisolver, fonttools, cycler, contourpy, matplotlib, captum\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0.1\n",
      "    Uninstalling PyYAML-6.0.1:\n",
      "      Successfully uninstalled PyYAML-6.0.1\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 5.9.8\n",
      "    Uninstalling psutil-5.9.8:\n",
      "      Successfully uninstalled psutil-5.9.8\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.2\n",
      "    Uninstalling packaging-23.2:\n",
      "      Successfully uninstalled packaging-23.2\n",
      "Successfully installed captum-0.6.0 contourpy-1.2.0 cycler-0.12.1 fonttools-4.49.0 kiwisolver-1.4.5 matplotlib-3.8.3 packaging-23.1 psutil-5.9.5 pynvml-11.4.1 pyparsing-3.1.2 pyyaml-6.0\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mCollecting torchserve==0.8.2\n",
      "  Downloading torchserve-0.8.2-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting torch-model-archiver==0.8.2\n",
      "  Downloading torch_model_archiver-0.8.2-py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from torchserve==0.8.2) (10.2.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from torchserve==0.8.2) (5.9.5)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from torchserve==0.8.2) (23.1)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from torchserve==0.8.2) (0.42.0)\n",
      "Collecting enum-compat (from torch-model-archiver==0.8.2)\n",
      "  Downloading enum_compat-0.0.3-py3-none-any.whl.metadata (954 bytes)\n",
      "Downloading torchserve-0.8.2-py3-none-any.whl (23.8 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 23.8/23.8 MB 170.2 MB/s eta 0:00:00\n",
      "Downloading torch_model_archiver-0.8.2-py3-none-any.whl (14 kB)\n",
      "Downloading enum_compat-0.0.3-py3-none-any.whl (1.3 kB)\n",
      "Installing collected packages: enum-compat, torchserve, torch-model-archiver\n",
      "Successfully installed enum-compat-0.0.3 torch-model-archiver-0.8.2 torchserve-0.8.2\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container d33a110aa968\n",
      " ---> b30c61a1c01a\n",
      "Step 32/42 : RUN useradd -m model-server  && mkdir -p /home/model-server/tmp /opt/ml/model  && chown -R model-server /home/model-server /opt/ml/model\n",
      " ---> Running in a148732408a3\n",
      "Removing intermediate container a148732408a3\n",
      " ---> 7aa071a692c1\n",
      "Step 33/42 : COPY torchserve-entrypoint.py /usr/local/bin/dockerd-entrypoint.py\n",
      " ---> ce339c6bee5e\n",
      "Step 34/42 : COPY config.properties /home/model-server\n",
      " ---> 4fb6e5d3e50e\n",
      "Step 35/42 : RUN chmod +x /usr/local/bin/dockerd-entrypoint.py\n",
      " ---> Running in ae238fe11767\n",
      "Removing intermediate container ae238fe11767\n",
      " ---> d1d999dc69eb\n",
      "Step 36/42 : RUN HOME_DIR=/root  && curl -o ${HOME_DIR}/oss_compliance.zip https://aws-dlinfra-utilities.s3.amazonaws.com/oss_compliance.zip  && unzip ${HOME_DIR}/oss_compliance.zip -d ${HOME_DIR}/  && cp ${HOME_DIR}/oss_compliance/test/testOSSCompliance /usr/local/bin/testOSSCompliance  && chmod +x /usr/local/bin/testOSSCompliance  && chmod +x ${HOME_DIR}/oss_compliance/generate_oss_compliance.sh  && ${HOME_DIR}/oss_compliance/generate_oss_compliance.sh ${HOME_DIR} ${PYTHON}  && rm -rf ${HOME_DIR}/oss_compliance*\n",
      " ---> Running in 2d79d2dda63e\n",
      "\u001b[91mcurl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\n",
      "\u001b[0m\u001b[91m  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  127k  100  127k    0     0  1325k      0 --:--:-- --:--:-- --:--:-- 1329k\u001b[0m\u001b[91m\n",
      "\u001b[0mArchive:  /root/oss_compliance.zip\n",
      "   creating: /root/oss_compliance/\n",
      "   creating: /root/oss_compliance/test/\n",
      "  inflating: /root/oss_compliance/test/testOSSCompliance  \n",
      "   creating: /root/oss_compliance/third_party_licenses_for_non_blessed_licenses/\n",
      "  inflating: /root/oss_compliance/third_party_licenses_for_non_blessed_licenses/create_license_attribution_text_file.py  \n",
      "  inflating: /root/oss_compliance/third_party_licenses_for_non_blessed_licenses/github_handler.py  \n",
      "  inflating: /root/oss_compliance/third_party_licenses_for_non_blessed_licenses/README.md  \n",
      "   creating: /root/oss_compliance/build_from_source_packages/\n",
      "  inflating: /root/oss_compliance/build_from_source_packages/BUILD_FROM_SOURCE_PACKAGES_LICENCES_ALL_IMAGES  \n",
      "  inflating: /root/oss_compliance/build_from_source_packages/BUILD_FROM_SOURCE_PACKAGES_LICENCES_AARCH64_IMAGES  \n",
      "  inflating: /root/oss_compliance/generate_oss_compliance.sh  \n",
      "  inflating: /root/oss_compliance/README.md  \n",
      "   creating: /root/oss_compliance/python_packages/\n",
      "   creating: /root/oss_compliance/python_packages/generate_licenses/\n",
      "  inflating: /root/oss_compliance/python_packages/generate_licenses/manage_licenses_warnings.py  \n",
      "  inflating: /root/oss_compliance/python_packages/generate_licenses/create_license_attribution_text_file.py  \n",
      "  inflating: /root/oss_compliance/python_packages/generate_licenses/github_handler.py  \n",
      "  inflating: /root/oss_compliance/python_packages/generate_licenses/pull_missing_info.py  \n",
      "  inflating: /root/oss_compliance/python_packages/generate_licenses/process_licenses_json_file.py  \n",
      "   creating: /root/oss_compliance/python_packages/generate_licenses/datafiles/\n",
      "   creating: /root/oss_compliance/python_packages/generate_licenses/datafiles/licenses/\n",
      "   creating: /root/oss_compliance/python_packages/generate_licenses/datafiles/licenses/generic_licenses/\n",
      "  inflating: /root/oss_compliance/python_packages/generate_licenses/datafiles/licenses/generic_licenses/ZPL_2  \n",
      "  inflating: /root/oss_compliance/python_packages/generate_licenses/datafiles/licenses/generic_licenses/MPL_2  \n",
      "  inflating: /root/oss_compliance/python_packages/generate_licenses/datafiles/licenses/generic_licenses/LGPL_2  \n",
      "  inflating: /root/oss_compliance/python_packages/generate_licenses/datafiles/licenses/generic_licenses/LGPL_3  \n",
      "  inflating: /root/oss_compliance/python_packages/generate_licenses/datafiles/licenses/generic_licenses/HPND  \n",
      "  inflating: /root/oss_compliance/python_packages/generate_licenses/datafiles/licenses/generic_licenses/Apache_1  \n",
      "  inflating: /root/oss_compliance/python_packages/generate_licenses/datafiles/licenses/generic_licenses/BSD_2  \n",
      "  inflating: /root/oss_compliance/python_packages/generate_licenses/datafiles/licenses/generic_licenses/Continuum  \n",
      "  inflating: /root/oss_compliance/python_packages/generate_licenses/datafiles/licenses/generic_licenses/BSD_3  \n",
      "  inflating: /root/oss_compliance/python_packages/generate_licenses/datafiles/licenses/generic_licenses/ISC  \n",
      "  inflating: /root/oss_compliance/python_packages/generate_licenses/datafiles/licenses/generic_licenses/Expatlicense  \n",
      "  inflating: /root/oss_compliance/python_packages/generate_licenses/datafiles/licenses/generic_licenses/GPL_3  \n",
      "  inflating: /root/oss_compliance/python_packages/generate_licenses/datafiles/licenses/generic_licenses/GPL_2  \n",
      "  inflating: /root/oss_compliance/python_packages/generate_licenses/datafiles/licenses/generic_licenses/PSF  \n",
      "  inflating: /root/oss_compliance/python_packages/generate_licenses/datafiles/licenses/generic_licenses/MIT  \n",
      "  inflating: /root/oss_compliance/python_packages/generate_licenses/datafiles/licenses/generic_licenses/Apache_2  \n",
      "   creating: /root/oss_compliance/python_packages/generate_licenses/datafiles/missing_packages_info/\n",
      "  inflating: /root/oss_compliance/python_packages/generate_licenses/datafiles/missing_packages_info/blessed_packages.json  \n",
      "  inflating: /root/oss_compliance/python_packages/generate_licenses/datafiles/missing_packages_info/missing_licenses_info.json  \n",
      "  inflating: /root/oss_compliance/python_packages/generate_licenses/datafiles/missing_packages_info/license_categories.json  \n",
      "   creating: /root/oss_compliance/python_packages/piplicenses/\n",
      "  inflating: /root/oss_compliance/python_packages/piplicenses/requirements.txt  \n",
      "  inflating: /root/oss_compliance/python_packages/piplicenses/piplicenses.py  \n",
      "   creating: /root/oss_compliance/python_packages/piplicenses/datafiles/\n",
      "  inflating: /root/oss_compliance/python_packages/piplicenses/datafiles/package_directory_mapping.json  \n",
      "   creating: /root/oss_compliance/linux_packages/\n",
      "  inflating: /root/oss_compliance/linux_packages/ubuntu_packages.py  \n",
      "  inflating: /root/oss_compliance/linux_packages/amazon_linux_packages.py  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PTable (from -r /root/oss_compliance/python_packages/piplicenses/requirements.txt (line 2))\n",
      "  Downloading PTable-0.9.2.tar.gz (31 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: PTable\n",
      "  Building wheel for PTable (setup.py): started\n",
      "  Building wheel for PTable (setup.py): finished with status 'done'\n",
      "  Created wheel for PTable: filename=PTable-0.9.2-py3-none-any.whl size=22907 sha256=34cce791d894fb9119938f350f8f50a824f1581f737f9d17e415f50cf2986680\n",
      "  Stored in directory: /root/.cache/pip/wheels/bc/88/52/f2e9fc70f3a657cf256e9b01a8a42938c4c5ee69118d51ed90\n",
      "Successfully built PTable\n",
      "Installing collected packages: PTable\n",
      "Successfully installed PTable-0.9.2\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\u001b[91m/root/oss_compliance/python_packages/piplicenses/piplicenses.py:39: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n",
      "\u001b[0mPath doesnt exists /opt/conda/lib/python3.10/site-packages/fonttools\n",
      "Path doesnt exists /opt/conda/lib/python3.10/site-packages/fonttools\n",
      "Path doesnt exists /opt/conda/lib/python3.10/site-packages/intel_openmp\n",
      "Path doesnt exists /opt/conda/lib/python3.10/site-packages/intel_openmp\n",
      "Path doesnt exists /opt/conda/lib/python3.10/site-packages/oneccl_bind_pt\n",
      "Path doesnt exists /opt/conda/lib/python3.10/site-packages/oneccl_bind_pt\n",
      "Path doesnt exists /opt/conda/lib/python3.10/site-packages/ruamel.yaml\n",
      "Path doesnt exists /opt/conda/lib/python3.10/site-packages/ruamel.yaml\n",
      "Path doesnt exists /opt/conda/lib/python3.10/site-packages/ruamel.yaml.clib\n",
      "Path doesnt exists /opt/conda/lib/python3.10/site-packages/ruamel.yaml.clib\n",
      "Path doesnt exists /opt/conda/lib/python3.10/site-packages/sagemaker_pytorch_inference\n",
      "Path doesnt exists /opt/conda/lib/python3.10/site-packages/sagemaker_pytorch_inference\n",
      "created path: /root/oss_compliance/python_packages/piplicenses/PACKAGES_LICENSES_JSON.json\n",
      "No repository found for package: safetensors. You can fix it by adding package to missing_licenses_info.json file by adding 'source_code_url' key\n",
      "No license file found for package: safetensors\n",
      "{'no_url': ['package menuinst has no url info but it is not needed', 'package kiwisolver has no url info but it is not needed', 'package cryptography has no url info but it is not needed', 'package traitlets has no url info but it is not needed', 'package conda has no url info but it is not needed', 'package contourpy has no url info but it is not needed', 'package conda-libmamba-solver has no url info but it is not needed', 'package pygments has no url info but it is not needed', 'package pillow has no url info but it is not needed', 'package tiktoken has no url info but it is not needed', 'package ruamel.yaml has no url info but it is not needed', 'package tqdm has no url info but it is not needed', 'package colorama has no url info but it is not needed', 'package idna has no url info but it is not needed', 'package networkx has no url info but it is not needed', 'package packaging has no url info but it is not needed'], 'no_notice': ['package accelerate has no notice info', 'package huggingface-hub has no notice info'], 'no_license': ['package safetensors has missing license text.']}\n",
      "Found existing installation: PTable 0.9.2\n",
      "Uninstalling PTable-0.9.2:\n",
      "  Successfully uninstalled PTable-0.9.2\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m/root/PYTHON_PACKAGES_LICENSES exists.\n",
      "/root/LINUX_PACKAGES_LICENSES exists.\n",
      "/root/BUILD_FROM_SOURCE_PACKAGES_LICENCES exists.\n",
      "Removing intermediate container 2d79d2dda63e\n",
      " ---> 49e7efcf30b7\n",
      "Step 37/42 : RUN pip cache purge  && rm -rf /tmp/tmp*  && rm -iRf /root/.cache\n",
      " ---> Running in eba7f6db57e5\n",
      "Files removed: 13\n",
      "Removing intermediate container eba7f6db57e5\n",
      " ---> 0a98aab6f45d\n",
      "Step 38/42 : ENV KMP_SETTINGS=1\n",
      " ---> Running in 42077c12b446\n",
      "Removing intermediate container 42077c12b446\n",
      " ---> 9d052ba78383\n",
      "Step 39/42 : ENV LD_PRELOAD=\"/usr/lib/x86_64-linux-gnu/libjemalloc.so:/opt/conda/lib/libiomp5.so:${LD_PRELOAD}\"\n",
      " ---> Running in c6d8b5060fdd\n",
      "Removing intermediate container c6d8b5060fdd\n",
      " ---> bffc4eba1817\n",
      "Step 40/42 : EXPOSE 8080 8081\n",
      " ---> Running in becfcc37bcd9\n",
      "Removing intermediate container becfcc37bcd9\n",
      " ---> e1fa49a3853a\n",
      "Step 41/42 : ENTRYPOINT [\"python\", \"/usr/local/bin/dockerd-entrypoint.py\"]\n",
      " ---> Running in eca44e9cf30d\n",
      "Removing intermediate container eca44e9cf30d\n",
      " ---> 4fb9f8a06006\n",
      "Step 42/42 : CMD [\"torchserve\", \"--start\", \"--ts-config\", \"/home/model-server/config.properties\", \"--model-store\", \"/home/model-server/\"]\n",
      " ---> Running in 2c0cac582d66\n",
      "Removing intermediate container 2c0cac582d66\n",
      " ---> aab398359b9e\n",
      "Successfully built aab398359b9e\n",
      "Successfully tagged 205130860845.dkr.ecr.us-west-2.amazonaws.com/pytorch_inference:2.2.0-cpu-intel-py310-ubuntu20.04-sagemaker-codegen-2024-03-08-14-05-25\n"
     ]
    }
   ],
   "source": [
    "# build docker image\n",
    "!docker build -t $ECR_URL docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4982c1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\r\n",
      "Configure a credential helper to remove this warning. See\r\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\r\n",
      "\r\n",
      "Login Succeeded\r\n"
     ]
    }
   ],
   "source": [
    "# Authenticate to ECR\n",
    "!aws ecr get-login-password --region {REGION} | docker login --username AWS --password-stdin {ACCOUNT_ID}.dkr.ecr.{REGION}.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17e07c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [205130860845.dkr.ecr.us-west-2.amazonaws.com/pytorch_inference]\n",
      "\n",
      "\u001b[1B6dbbae6c: Preparing \n",
      "\u001b[1Bed8b56a6: Preparing \n",
      "\u001b[1Be530a422: Preparing \n",
      "\u001b[1Bef9f7289: Preparing \n",
      "\u001b[1Bc00388c2: Preparing \n",
      "\u001b[1B7c01c12a: Preparing \n",
      "\u001b[1Bdce3d9a0: Preparing \n",
      "\u001b[1B1dcac4b3: Preparing \n",
      "\u001b[1B850ed2d1: Preparing \n",
      "\u001b[1Bce5ff191: Preparing \n",
      "\u001b[1Bccc317b3: Preparing \n",
      "\u001b[1B4f7a5ea5: Preparing \n",
      "\u001b[1B50ce8c77: Preparing \n",
      "\u001b[1B6df6acab: Preparing \n",
      "\u001b[1B1bf48f86: Preparing \n",
      "\u001b[1B5a4c4867: Preparing \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[7Bccc317b3: Pushing    744MB/792.1MB\u001b[15A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[13A\u001b[2K\u001b[17A\u001b[2K\u001b[12A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[10A\u001b[2K\u001b[9A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[16A\u001b[2K\u001b[9A\u001b[2K\u001b[10A\u001b[2K\u001b[9A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[8A\u001b[2K\u001b[10A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[11A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[9A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[11A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[11A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[10A\u001b[2K\u001b[8A\u001b[2K\u001b[11A\u001b[2K\u001b[8A\u001b[2K\u001b[9A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[10A\u001b[2K\u001b[9A\u001b[2K\u001b[11A\u001b[2K\u001b[8A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[9A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[10A\u001b[2K\u001b[9A\u001b[2K\u001b[11A\u001b[2K\u001b[8A\u001b[2K\u001b[11A\u001b[2K\u001b[8A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[9A\u001b[2K\u001b[10A\u001b[2K\u001b[8A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[10A\u001b[2K\u001b[8A\u001b[2K\u001b[11A\u001b[2K\u001b[7A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[8A\u001b[2K\u001b[11A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[8A\u001b[2K\u001b[11A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[9A\u001b[2K\u001b[11A\u001b[2K\u001b[8A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[9A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[10A\u001b[2K\u001b[8A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[9A\u001b[2K\u001b[10A\u001b[2K\u001b[8A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[10A\u001b[2K\u001b[9A\u001b[2K\u001b[11A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[9A\u001b[2K\u001b[10A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[9A\u001b[2K\u001b[10A\u001b[2K\u001b[9A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[8A\u001b[2K\u001b[10A\u001b[2K\u001b[9A\u001b[2K\u001b[11A\u001b[2K\u001b[8A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[11A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[9A\u001b[2K\u001b[10A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[8A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[9A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[8A\u001b[2K\u001b[10A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[10A\u001b[2K\u001b[8A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[9A\u001b[2K\u001b[10A\u001b[2K\u001b[9A\u001b[2K\u001b[10A\u001b[2K\u001b[8A\u001b[2K\u001b[10A\u001b[2K\u001b[8A\u001b[2K\u001b[10A\u001b[2K\u001b[8A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[8A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[9A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[11A\u001b[2K\u001b[8A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[8A\u001b[2K\u001b[9A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[9A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[11A\u001b[2K\u001b[8A\u001b[2K\u001b[9A\u001b[2K\u001b[10A\u001b[2K\u001b[9A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[8A\u001b[2K\u001b[9A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[8A\u001b[2K\u001b[9A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[8A\u001b[2K\u001b[11A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[10A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[11A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[10A\u001b[2K\u001b[9A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[11A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[10A\u001b[2K\u001b[8A\u001b[2K\u001b[10A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[9A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[8A\u001b[2K\u001b[10A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[10A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[10A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[5A\u001b[2K\u001b[10A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[10A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[5A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[8A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[5A\u001b[2K\u001b[10A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2KPushing  601.1MB/792.1MB\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[7Bccc317b3: Pushed   806.2MB/792.1MB\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K2.2.0-cpu-intel-py310-ubuntu20.04-sagemaker-codegen-2024-03-08-14-05-25: digest: sha256:45cf2dccdc3176062cab8016194379a85bfece4f2018478c9a17b61fb8b56e7e size: 3898\n"
     ]
    }
   ],
   "source": [
    "# Push docker image\n",
    "!docker push $ECR_URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66223ab",
   "metadata": {},
   "source": [
    "### Create a Torchserve file and put it on S3 bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214eb033",
   "metadata": {},
   "source": [
    "The endpoint has been tested on `Salesforce/codegen25-7b-multi` model. Here's how to create a torchserve file and put it on S3 bucket required to run the endpoint with Deep Learning Containers.\n",
    "\n",
    "In order to change batch size, max length or max new tokens of the model, modify fields in model-config.yaml before creating the Torchserve file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ae63f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minWorkers: 1\r\n",
      "maxWorkers: 1\r\n",
      "responseTimeout: 1500\r\n",
      "\r\n",
      "handler:\r\n",
      "    model_name: \"Salesforce/codegen25-7b-multi\"\r\n",
      "    batch_size: 1\r\n",
      "    max_length: 128\r\n",
      "    max_new_tokens: 32\r\n",
      "    ipex_weight_only_quantization: true\r\n",
      "    woq_dtype: \"INT8\"\r\n",
      "    lowp_mode: \"BF16\"\r\n",
      "    act_quant_mode: \"PER_IC_BLOCK\"\r\n",
      "    group_size: -1\r\n",
      "    token_latency: true\r\n",
      "    benchmark: true \r\n",
      "    num_warmup: 2\r\n",
      "    num_iter: 8\r\n",
      "    greedy: true\r\n",
      "    \r\n"
     ]
    }
   ],
   "source": [
    "!cd codegen_model && cat model-config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e5a88d",
   "metadata": {},
   "source": [
    "To generate a Torchserve file use following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "beff88a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING - Overwriting /home/ec2-user/SageMaker/aws-sagemaker-intel-quantization/codegen_example/codegen_model/codegen25.tar.gz ...\r\n"
     ]
    }
   ],
   "source": [
    "!cd codegen_model && torch-model-archiver --force --model-name codegen25 --version 1.0 --handler codegen_handler.py --config-file model-config.yaml --extra-files codegen25.py --archive-format tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee51df9e",
   "metadata": {},
   "source": [
    "Next, copy the model into an S3 bucket of your choice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "79ee99be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 5.1 KiB/5.1 KiB (47.0 KiB/s) with 1 file(s) remaining\r",
      "upload: ./codegen25.tar.gz to s3://intel-sagemaker/codegen25.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "!cd codegen_model && aws s3 cp codegen25.tar.gz $S3_BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5596150e",
   "metadata": {},
   "source": [
    "### Create AWS Sagemaker endpoint\n",
    "\n",
    "Next step is to deploy the model to AWS Sagemaker and create an endpoint in order to run inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a99b2232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "account=205130860845, region=us-west-2, role=arn:aws:iam::205130860845:role/sagemaker_fullaccess, output_path=s3://sagemaker-us-west-2-205130860845/torchserve\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "boto3_session = boto3.session.Session(region_name=REGION)\n",
    "smr = boto3.client('sagemaker-runtime')\n",
    "sm = boto3.client('sagemaker')\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.session.Session(boto3_session, sagemaker_client=sm, sagemaker_runtime_client=smr)\n",
    "region = sess._region_name\n",
    "account = sess.account_id()\n",
    "\n",
    "bucket_name = sess.default_bucket()\n",
    "prefix = \"torchserve\"\n",
    "output_path = f\"s3://{bucket_name}/{prefix}\"\n",
    "print(f'account={account}, region={region}, role={role}, output_path={output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d557191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codegen-ipex-2024-03-08-14-09-28-465\n",
      "<sagemaker.model.Model object at 0x7f985c6cf220>\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import Model\n",
    "\n",
    "instance_type = \"ml.m7i.8xlarge\"\n",
    "sagemaker_name = sagemaker.utils.name_from_base(endpoint_name)\n",
    "\n",
    "model = Model(\n",
    "    name=\"torchserve-codegen-ipex\" + datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\"),\n",
    "    # Enable SageMaker uncompressed model artifacts\n",
    "    model_data=S3_URL,\n",
    "    image_uri=ECR_URL,\n",
    "    role=role,\n",
    "    sagemaker_session=sess,\n",
    "    env={\"TS_INSTALL_PY_DEP_PER_MODEL\": \"true\",\n",
    "         \"SAGEMAKER_CONTAINER_LOG_LEVEL\": \"0\",\n",
    "         \"SAGEMAKER_REGION\": region},\n",
    ")\n",
    "print(sagemaker_name)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b3776da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    endpoint_name=sagemaker_name,\n",
    "    #volume_size=32, # increase the size to store large model\n",
    "    model_data_download_timeout=3600, # increase the timeout to download large model\n",
    "    container_startup_health_check_timeout=600, # increase the timeout to load large model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8aa9274",
   "metadata": {},
   "source": [
    "You can inspect the logs to check whether the model has been deployed successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bb84e6",
   "metadata": {},
   "source": [
    "### Invoke the endpoint\n",
    "\n",
    "Once the model is deployed, invoke the sample response with following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1132b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, json\n",
    "\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "task = \"Write a python function to compute the factorial of an integer.\"\n",
    "\n",
    "custom_attributes = \"c000b4f9-df62-4c85-a0bf-7c525f9104a4\"  # An example of a trace ID.\n",
    "content_type = \"text/plain\"                           # The MIME type of the input data in the request body.\n",
    "accept = \"*/*\"                                              # The desired MIME type of the inference in the response.\n",
    "\n",
    "import io\n",
    "\n",
    "class Parser:\n",
    "    def __init__(self):\n",
    "        self.buff = io.BytesIO()\n",
    "        self.read_pos = 0\n",
    "        \n",
    "    def write(self, content):\n",
    "        self.buff.seek(0, io.SEEK_END)\n",
    "        self.buff.write(content)\n",
    "        data = self.buff.getvalue()\n",
    "        \n",
    "    def scan_lines(self):\n",
    "        self.buff.seek(self.read_pos)\n",
    "        for line in self.buff.readlines():\n",
    "            if line[-1] != b'\\n':\n",
    "                self.read_pos += len(line)\n",
    "                yield line[:-1]\n",
    "                \n",
    "    def reset(self):\n",
    "        self.read_pos = 0\n",
    "\n",
    "start_time = time.time()\n",
    "response = client.invoke_endpoint_with_response_stream(\n",
    "    EndpointName=sagemaker_name, \n",
    "    CustomAttributes=custom_attributes, \n",
    "    ContentType=content_type,\n",
    "    Accept=accept,\n",
    "    Body=task)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "parser = Parser()\n",
    "for event in response['Body']:\n",
    "    parser.write(event['PayloadPart']['Bytes'])\n",
    "    for line in parser.scan_lines():\n",
    "        print(\"\\n\", line.decode(\"utf-8\"), end=' \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bc9b67",
   "metadata": {},
   "source": [
    "### Clean up\n",
    "\n",
    "Once you will be done running the endpoint, you can delete it by using following method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "70d0cc31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '666d3bc9-4614-4f72-a267-66677e440ce4',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '666d3bc9-4614-4f72-a267-66677e440ce4',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Thu, 07 Mar 2024 17:42:18 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.delete_endpoint(EndpointName=sagemaker_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85d3983",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
