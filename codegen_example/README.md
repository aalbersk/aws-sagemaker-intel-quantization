# Deploy optimized LLM model with Intel速 Extension for PyTorch (IPEX) and Torchserve on AWS Sagemaker

## Description
This sample provide code to deploy a LLM model with Intel速 Extension for PyTorch (IPEX) with Torchserve on AWS Sagemaker on instances supporting 4th Gen Intel速 Xeon速 Scalable Processors. The notebook provided builds a Docker container, pushes it to AWS ECR, creates a torchserve file and puts in on AWS S3 bucket and creates and invokes an AWS Sagemaker endpoint. The pipeline was tested on [Codegen model](https://huggingface.co/Salesforce/codegen25-7b-multi_P).

## Execution
Please refer to [E2E-LLM-Sagemaker-IPEX.ipynb](E2E-LLM-Sagemaker-IPEX.ipynb) for more information.

## Human Rights Disclaimer
Intel is committed to respecting human rights and avoiding causing or directly contributing to adverse impacts on human rights. See [Intel's Global Human Rights Policy](https://www.intel.com/content/www/us/en/policy/policy-human-rights.html "Intel's Global Human Rights Policy"). The software licensed from Intel is intended for socially responsible applications and should not be used to cause or contribute to a violation of internationally recognized human rights.

&copy;Intel Corporation